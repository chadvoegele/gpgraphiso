import gg.ast.modifier
from gg.ast import Kernel, CBlock, Pipe, Iterate, Invoke, If, CDecl, WLInit, ASTNodeAnno, GlobalBarrier
from gg.ast.anno import Uniform, CallConfig
from gg.ast.params import *
import gg.passes
from gg.ast.utils import *
import gg.passes.kanno
from gg.ast.walkers import *
from gg.backend.cuda.anno import LaunchBounds
from gg.ast.misc.cblocks import ClosureEnvironment
from gg.tree import Tree, TNode
from gg.ast.callconfig import ShrinkableBlockTy, FixedBlockTy, call_config_compat_p
import gg.closure
from gg.symtab import STAsDict
from functools import reduce

class OutlinedKernelAnno(ASTNodeAnno):  # annotation as anno.outline on all kernels generated by IterOutliner
    wrapper = False
    outline = False
    host = False
    device = False
    pipe_name = ""
    clonable = False

    def __str__(self):
        return "wrapper: %s, outline: %s, host: %s, device: %s, pipe_name: %s" % (self.wrapper, self.outline, self.host, self.device, self.pipe_name)

class OriginalKernelAnno(ASTNodeAnno):
    clonable = True
    name = None

    def __init__(self, name):
        self.name = name

    def clone(self):
        return OriginalKernelAnno(self.name)

class CallConfigCompatible(ASTNodeAnno):
    clonable = False
    compatible = False
    #block_size = False

    def __init__(self, compatible = False, kcc = None):
        self.compatible = compatible
        self.kcc = kcc
        #self.block_size = block_size
        # TODO: launch bounds as well
        
    def __str__(self):
        return "CallConfigCompatible(compatible = %s)" % (compatible,)

# probably nicer to build as a AST subsetting-and-tranforming walker?
class PipeTreeBuilder(ASTPreOrderWalker):
    def __init__(self):
        self.parents = Stack()

    def generic_node_exit(self, node):
        if node == self.parents.top.data:
            self.parents.pop()

    def generic_node_visitor(self, node):
        if isinstance(node, Pipe) or isinstance(node, Iterate) or isinstance(node, Invoke):
            n = TNode(node)
            self.parents.top.add_child(n)
            self.parents.push(n)
    
        return True
            
    def get_kernel_pipe_tree(self, kernel):
        self.tree = Tree(kernel)
        self.parents.push(self.tree.root)
        self.visit(kernel)
        assert len(self.parents) == 0, len(self.parents)

        return self.tree

class PipeTreeAnalysis(object):
    def __init__(self, kernel, outliner):
        self.ol = outliner

        ptb = PipeTreeBuilder()
        self.tree = ptb.get_kernel_pipe_tree(kernel)

    def _label_ctx(self, node, parent, depth, data):
        if not isinstance(node.data, (Pipe, Iterate)):
            return

        if depth == 1:
            assert isinstance(parent.data, Kernel)
            node.pipe_ctx = "pipe_%s" % (parent.children.index(node),)
        else:
            node.pipe_ctx = parent.pipe_ctx

    def _okay_to_outline(self, node, parent, depth, data):
        node.okay = False
        node.depth = depth
        ast_node = node.data
    
        # this was to avoid multi-trees
        if isinstance(ast_node, Kernel):
            return 

        if not ast_node.check_gen(self.ol.gen): 
            # TODO: earlier we checked only top node?
            return

        if isinstance(ast_node, (Iterate, Invoke)):
            k = ast_node.kernel
            ki = self.ol.unit.kernels[k]
            if ki.prio_wl:
                self.ol.compiler.info("'%s' uses priority, not outlining" % (k,))
                return

        if isinstance(ast_node, Invoke):
            return

        node.okay = all([n.okay for n in node.children if not isinstance(n.data, Invoke)])

    def _outlinable(self, node, parent, depth, data):
        if node.okay and depth >= 1:
            ast_node = node.data
            if ast_node._call is None and not ast_node.has_anno("closure"): 
                self.ol.compiler.info("'%s' does not have ClosureHint, not outlining" % (ast_node,))
                return True # continue search

            if not ast_node.has_anno("closure"):
                self.ol.compiler.log.error("_call and _sign are obsolete, use ClosureHint instead, not outlining") 
                return True # continue search

            # node has closure anno
            data.append(node)
            return False # stop searching

        return True # continue search

    def check_nodes(self):
        self.tree.dfs(self._okay_to_outline, order="post")
        outlinable_pipes = []
        self.tree.dfs(self._outlinable, data = outlinable_pipes)
        if len(outlinable_pipes):
            # TODO This must be done in a separate pass
            self.tree.dfs(self._label_ctx)

        return outlinable_pipes

    def _flatten(self, node, parent, depth, data):
        assert not isinstance(node.data, (Pipe, Iterate)) or node.okay, node
        data.append(node)

    def get_all_children(self, outpipe):
        children = []
        self.tree.dfs(self._flatten, node=outpipe, data = children)
        return children

    def dump(self):
        def p(n, p, d, dd):
            print(" "*d, n, n.okay, n.depth, n.data, p)

        self.tree.bfs(p)

class IterPipeOutliner(gg.ast.modifier.ASTModifier):
    def _needs_retval(self, pipe):
        for i in pipe:
            if isinstance(i, Pipe):
                continue
            elif isinstance(i, Iterate):
                k = i.kernel

                if i.condition != "WL":
                    return True
            elif isinstance(i, Invoke):
                # current implementation does not support ANY|ALL
                continue
            else:
                assert False

        return False

    def _param_list(self, pipe):
        out = []
        head = pipe[0]
        added = set()

        closure = None
        if head.has_anno("closure"):
            closure = head.anno.closure

        for i in pipe:
            if isinstance(i, Pipe):
                continue
            elif isinstance(i, Iterate) or isinstance(i, Invoke):
                k = i.kernel

            if k in added:
                continue

            added.add(k)

            if self.unit.kernels[k].contains_barrier and self.unit.kernels[k].barrier_level == 0:
                if closure:
                    gbn = '%s_barrier' % (k,)
                    bkn = '%s_blocks' % (k,)

                    if not closure.has_var(gbn):
                        closure.add(gbn, ('GlobalBarrier&', gbn), gbn, ('GlobalBarrier', gbn), gbn)
                        closure.add(bkn, ('int', bkn), bkn, ('int', bkn), bkn)

                out.append(('GlobalBarrier&', '%s_barrier' % (k)))
                out.append(('int', '%s_blocks' % (k)))

                assert head._call is None

        return out

    def _gpu_kernel(self, name, pipe, hk, save_pipe = False):
        rv = False

        assert pipe[0].has_anno("closure")
        args = [x.decl for x in pipe[0].anno.closure.items("cpu", "gpu")]

        if self._needs_retval(pipe):
            # note: this needs to added because the gpu kernel can't
            # pass a local variable to a DP kernel, so the dispatch
            # function creates a global variable which we pass around.

            # TODO: this is a GPU only parameter and needs to be handled within the Closure

            args = args + [('int*', 'retval')]
            rv = True

        xwritten = self._closure_writes(pipe[0].anno.closure.xaddr)
        xwr_init = []
        xwr_copyback = []
        if xwritten is not None:
            xwr_decls = [(ty + "*", "cl_" + v) for v, ty in xwritten]
            args += xwr_decls
            
            for v, ty in xwritten:
                xwr_init.append("%s = *cl_%s" % (v, v))
                xwr_copyback.append("*cl_%s = %s" % (v, v))
                
        x = Kernel(hk.name + "_gpu", args, hk.stmts.clone())
        x.stmts.stmts[0]._nn = name

        if len(xwr_init):
            x.stmts.stmts.insert(0, CBlock(xwr_init))

        if len(xwr_copyback) or save_pipe:
            x.stmts.stmts.append(If("tid == 0", [CondC(save_pipe, CBlock("pipe.save()")), 
                                                 CondC(len(xwr_copyback), CBlock(xwr_copyback))]))

        x.anno.outline = OutlinedKernelAnno(outline = True, device = True, pipe_name = name)

        return rv, x

    def _closure_writes(self, closure):
        out = []
        for v in sorted(closure.writes):
            ty = gg.closure.TypeTraits(closure.ty[v])
            if ty.is_primitive(): 
                out.append((v, closure.ty[v]))
            else:
                return None

        return out
                        
    def _wrapper(self, retval, hpipe, host, gpu, save_pipe = False):
        assert hpipe.has_anno("closure")
        call = [x.init for x in hpipe.anno.closure.items('cpu', 'cpu')]
        gpu_call = [x.init for x in hpipe.anno.closure.items('cpu', 'gpu')]
        gpu_call2 = [x for x in gpu_call if x not in ('blocks', 'threads')] # TODO: this is brittle

        if retval:
            # see note in _gpu_kernel

            gpu_call.append("retval.gpu_wr_ptr()")
            gpu_call2.append("retval.gpu_wr_ptr()")

        xwritten = self._closure_writes(hpipe.anno.closure.xaddr)
        xwr_decls = None
        xwr_alloc = []
        xwr_init = []
        xwr_copyback = []
        xwr_dealloc = []

        if xwritten is not None:
            xwr_decls = CDecl([(ty + "*", "cl_" + v, "") for v, ty in xwritten])

            # TODO: build this as a structure? (will need module level declaration)
            for v, ty in xwritten:
                xwr_alloc.append("check_cuda(cudaMalloc(&cl_%s, sizeof(%s) * 1))" % (v, ty))
                xwr_init.append("check_cuda(cudaMemcpy(cl_%s, &%s, sizeof(%s) * 1, cudaMemcpyHostToDevice))" % (v, v, ty))
                xwr_copyback.append("check_cuda(cudaMemcpy(&%s, cl_%s, sizeof(%s) * 1, cudaMemcpyDeviceToHost))" % (v, v, ty))
                xwr_dealloc.append("check_cuda(cudaFree(cl_%s))" % (v,))
                gpu_call.append('cl_' + v)
                gpu_call2.append('cl_' + v)

        stmts =[]
        if retval:
            stmts.append(CDecl(("Shared<int>", "retval", "(1)")))

        time_gpu_pipes = False
        if time_gpu_pipes:
            stmts.append(CDecl(('ggc::Timer', 't', '("%s")' % (hpipe._nn,))))
            stmts.append(CBlock("t.start()"))

        stmts.append(If("false",
                        [CBlock("%s(%s)" % (host.name, ",".join(call)))],
                        [CondC(len(xwr_alloc), xwr_decls),
                         CondC(len(xwr_alloc), CBlock(xwr_alloc + xwr_init, parse=False)),
                         CondC(save_pipe, CBlock("pipe.prep()")),
                         #TODO: _gb can fail later currently due to incompatible call configs. 
                         # This means that call configs must be decided here.
                         CBlock([CondC(time_gpu_pipes, 
                                       'fprintf(stderr, "using gpu pipe %s\\n")' % hpipe._nn, ''),
                                 CondC(not self.compiler.options.outline_iterate_gb, 
                                       "%s<<<1,1>>>(%s)" % (gpu.name, ",".join(gpu_call)),
                                       "// %s<<<1,1>>>(%s)" % (gpu.name, ",".join(gpu_call)),
                                       ),
                                 CondC(not self.compiler.options.outline_iterate_gb, 
                                       "// %(n)s_gb<<<%(n)s_gb_blocks, __tb_%(n)s_gb>>>(%(a)s, %(n)s_gb_barrier)" % {'n': gpu.name, 
                                                                                                                     'a': ",".join(gpu_call2)},
                                       "%(n)s_gb<<<%(n)s_gb_blocks, __tb_%(n)s_gb>>>(%(a)s, %(n)s_gb_barrier)" % {'n': gpu.name, 'a': 
                                                                                                   ",".join(gpu_call2)}
                                       ),
                                 ], parse = False),
                         CondC(save_pipe, CBlock("pipe.restore()")),
                         CondC(len(xwr_alloc), CBlock(xwr_copyback + xwr_dealloc, parse=False)),
                         ]
                        )
                     )

        if time_gpu_pipes:
            # debug only
            stmts.append(CBlock(["check_cuda(cudaDeviceSynchronize())",
                                 "t.stop()",
                                 'printf("%s %%llu ns\\n", t.duration())' % (hpipe._nn,)
                                 ])
                         )
            

        W = Kernel("%s_wrapper" % (hpipe._nn,), host.args, stmts, host=True)
        W.anno.outline = OutlinedKernelAnno(wrapper = True, host = True, pipe_name = hpipe._nn)
        return W

    def _needs_pipe(self, pipes_iterates):
        for n in pipes_iterates:
            if isinstance(n, Pipe):
                return True

            if isinstance(n, Iterate) and n.condition == "WL":                
                return True

            k = n.kernel
            if self.unit.kernels[k].contains_wl:
                return True            

    def _mark_kernels(self, pipes_iterates):        
        for n in pipes_iterates:
            if isinstance(n, Pipe):
                continue

            assert isinstance(n, (Iterate, Invoke))
            self.unit.outlined_kernels.add(n.kernel)

    def visit_Kernel(self, node): 
        if hasattr(node.anno, "outline"):
            return node

        self.kernel = node

        pta = PipeTreeAnalysis(node, self)
        outpipes = pta.check_nodes()
        #pta.dump()
        
        out = [super(IterPipeOutliner, self).visit_Kernel(node)]

        for op in outpipes:
            #print op
            p = op.pipe_ctx
            pp = [op.data] + [x.data for x in pta.get_all_children(op)]
            if True:
                head = pp[0]
                assert head.has_anno("closure")
                self._param_list(pp)

                save_pipe = False
                if self._needs_pipe(pp):
                    save_pipe = True
                    if not head.anno.closure.has_var("pipe"):
                        head.anno.closure.add("pipe", PipeParam("pipe", ref=True), "pipe", PipeParam("pipe", ref=False), "pipe")

                if not head.anno.closure.has_var("blocks"):
                    head.anno.closure.add("blocks", ('dim3&',  'blocks'), "blocks", ('dim3', 'blocks'), "blocks")
                    head.anno.closure.add("threads", ('dim3&',  'threads'), "threads", ('dim3', 'threads'), "threads")

                params = [x[1] for x in head.anno.closure.items("cpu", "cpu")]
                #print params
                for i, (ty, v) in enumerate(params): # TODO: move this inside closure.items()
                    if v in head.anno.closure.saddr.writes:
                        params[i] = (ty + "&", v) # TODO: make sure this is not already a &?

                head._nn = "%s_%s" % (node.name, p)
                
                hc = head.clone()

                # WHY?? init vs worklist_init
                if isinstance(head, Pipe):
                    save_pipe = save_pipe and head.init is None
                    hc.init = None 
                elif isinstance(head, Iterate):
                    save_pipe = save_pipe and head.worklist_init is None
                    hc.worklist_init = None

                hc._nn = head._nn
                
                #TODO: extra_cond references to host variables

                k = Kernel(head._nn, params, [hc], host = True)  # CPU Pipe kernel
                k.anno.outline = OutlinedKernelAnno(outline = True, host = True, pipe_name = head._nn)

                rv, g = self._gpu_kernel(hc._nn, pp, k, save_pipe = save_pipe)  # GPU Pipe Kernel
                wr = self._wrapper(rv, head, k, g, save_pipe = save_pipe) # Pipe dispatch kernel

                out.insert(0, wr)
                out.insert(0, g)
                out.insert(0, k)

                self.nodes_generated = True
                self._mark_kernels(pp)
                self.compiler.info('Outlined %s'% (head._nn))
            else:
                if node.check_gen(self.gen):
                    self.compiler.info('Failed to outline')

        return out

# dev/global prep
# identify kernels that can be gb-ified (all?)
# what about kernels that themselves use gbarriers?

class DevOnlyKernels(gg.ast.modifier.ASTModifier):
    def expand_kernel_params(self, node):
        # this is temporarily copied from cudagen 
        
        out = []

        for (t, p) in node.anno.kernel_params.params:
            if t == PARAM_WL:
                if node.device:
                    ty = "X&"
                else:
                    ty = "X"

                out.append((ty, "in_" + p))
                out.append((ty, "out_" + p))

                if node.contains_retry:
                    out.append((ty, "re_" + p))
            elif t == PARAM_EXCLUSIVE_LOCKS:
                out.append(('ExclusiveLocks', p))
            elif t == PARAM_GLOBAL_BARRIER:
                out.append(('GlobalBarrier', p))
            elif t == PARAM_RETVAL:
                out.append(('int *', p))
            else:
                assert False, t

        return out

    def visit_Kernel(self, node):
        if node.host or node.device:
            # not a __global__ kernel
            return node

        if node.has_anno("outline") and node.anno.outline.outline:
            # not a user-defined GPU kernel
            return node

        if not node.check_gen(self.gen):
            return node

        if node.name in self.unit.outlined_kernels: # This makes kernel name changing tricky
            nn = node.clone()
            nn.name += "_dev"
            nn.device = True

            nn.anno.original_kernel = OriginalKernelAnno(node.name)

            a = ", ".join([x[1] for x in nn.args + self.expand_kernel_params(node)])

            node.stmts.stmts = [CBlock("%s(%s)" % (nn.name, a), parse=False)]

            self.nodes_generated = True

            return [nn, node]

        return node

class RenameKernels(ASTWalker):
    def visit_Invoke(self, node):
        node.kernel = node.kernel + "_dev"
        
    def visit_Iterate(self, node):
        node.kernel = node.kernel + "_dev"

    @staticmethod
    def rename(node):
        assert isinstance(node, (Pipe, Iterate))
        x = RenameKernels()
        x.visit(node)

class PipeLaunchBounds(ASTWalker):
    def visit_Invoke(self, node):
        k = self.unit.kernels[node.kernel]
        
        if not k.device and k.has_anno2('cuda.launch_bounds'):
            self.launch_bounds.append(k.anno.cuda.launch_bounds)
        
    def visit_Iterate(self, node):
        k = self.unit.kernels[node.kernel]

        if not k.device and k.has_anno2('cuda.launch_bounds'):
            self.launch_bounds.append(k.anno.cuda.launch_bounds)
    
    @staticmethod
    def get_launch_bounds(unit, node):
        assert isinstance(node, (Pipe, Iterate))
        x = PipeLaunchBounds()
        x.unit = unit
        x.launch_bounds = []
        x.visit(node)

        if len(x.launch_bounds):
            lb = reduce(lambda lb1, lb2: lb1.combine(lb2), x.launch_bounds)
            return lb

        return None

class PipeCallConfig(ASTWalker):
    def visit_Invoke(self, node):
        k = self.unit.kernels[node.kernel]
        
        if not k.device and k.has_anno('call_config'):
            self.call_config[node.kernel] = k
        
    def visit_Iterate(self, node):
        k = self.unit.kernels[node.kernel]

        if not k.device and k.has_anno('call_config'):
            self.call_config[node.kernel] = k
    
    @staticmethod
    def get_call_config(unit, node):
        assert isinstance(node, (Pipe, Iterate))
        x = PipeCallConfig()
        x.unit = unit
        x.call_config = {}
        x.visit(node)

        if len(x.call_config):
            return x.call_config

        return None

                
class IterPipeOutlinerGBCheck(ASTWalker):
    def visit_Kernel(self, node):
        if not node.check_gen(self.gen):
            return node

        if not hasattr(node.anno, "outline"):
            return node
        
        if node.anno.outline.device and not node.anno.outline.wrapper and not node.has_anno("cc_compat"):
            ndx = 0
           
            if isinstance(node.stmts.stmts[ndx], CBlock): # the first statement is the closure copy-in (TODO, make this more robust)
                ndx = 1

                if isinstance(node.stmts.stmts[ndx], CDecl): # lighten_mode
                    ndx = 2

            cc = PipeCallConfig.get_call_config(self.unit, node.stmts.stmts[ndx])
            assert cc is not None, "Call configs are empty in Pipe!"

            lb = PipeLaunchBounds.get_launch_bounds(self.unit, node.stmts.stmts[ndx])
            if lb:
                kcc = ShrinkableBlockTy("__tb_" + node.name + "_gb", lb.bounds[None][0])
            else:
                kcc = ShrinkableBlockTy("__tb_" + node.name + "_gb", None)

            
            const = node.symtab.get_all_constants()

            # TODO: 256 value of TB_SIZE?
            const[None] = 'TB_SIZE'
            if 'TB_SIZE' not in const:
                const['TB_SIZE'] = 256

            compat, kcc = call_config_compat_p(kcc, [x.anno.call_config.block for x in cc.values()], 
                                               const)

            node.anno.cc_compat = CallConfigCompatible(compatible=compat, kcc = kcc)

class IterPipeOutlinerGB(IterPipeOutliner):
    def visit_Kernel(self, node):
        if not node.check_gen(self.gen):
            return node

        if not hasattr(node.anno, "outline"):
            return node
        
        if node.anno.outline.device and not node.anno.outline.wrapper:
            if not (node.has_anno("cc_compat") and node.anno.cc_compat.compatible):
                self.compiler.info("Unable to GB-ify %s, incompatible call configs in invoked kernels" % (node.name,))
                return node

            nn = node.clone()

            nn.name = nn.name + "_gb"
            nn.anno.outline = node.anno.outline

            ndx = 0
            
            if isinstance(nn.stmts.stmts[ndx], CBlock): # the first statement is the closure copy-in (TODO, make this more robust)
                ndx = 1

            nn.stmts.stmts[ndx]._nn = node.stmts.stmts[ndx]._nn

            if "lighten-wl" in self.compiler.options.hacks:
                nn.stmts.stmts.insert(ndx, CDecl([('PipeContextLight', 'pipe_light', '(pipe)'),
                                                  ('int', '_light_index', '= 0')]))
                ndx = ndx + 1

                save_block = nn.stmts.stmts[-1]
                if isinstance(save_block, gg.ast.If) and save_block.cond == "tid == 0":
                    save_pipe = save_block.true_stmts.stmts[0]
                    if isinstance(save_pipe, gg.ast.CBlock) and save_pipe.stmts[0] == "pipe.save()":
                        save_pipe.stmts.insert(0, "pipe_light.save(pipe, _light_index)")

            nn.args = [x for x in nn.args if x[0] != 'dim3&' and x[1] not in ('blocks', 'threads')]
            
            # TODO: if this is elastic, we can skip this ...?
            nn = LaunchBounds(nn, max_threads = node.anno.cc_compat.kcc.var)
            nn = CallConfig(nn, node.anno.cc_compat.kcc)

            RenameKernels.rename(nn.stmts.stmts[ndx])

            nn.stmts.stmts.insert(ndx + 1, GlobalBarrier().sync())

            self.nodes_generated = True
            return [nn, node]

        if node.anno.outline.wrapper:
            node.stmts.stmts.insert(0, GlobalBarrier().setup(node.anno.outline.pipe_name + "_gpu_gb"))

        return node

class CallChecker(ASTPreOrderWalker):
    def generic_node_visitor(self, node):
        if isinstance(node, (Pipe, Iterate)):
            if hasattr(node, '_call') and node._call is not None:
                complete, env = ClosureEnvironment().get_environment(self.compiler, node)

                call = set(node._call)

                for n, sym in env.items():
                    if n not in call and n == "pipe":
                        self.compiler.check_internal(False, "Pipe name '%s' used" % (n, ), node, _warn = True)
                        continue
                    
                    # TODO: handle shared variables correctly
                    self.compiler.check_internal(n in call or "Shared<%s>" % (n,) in call, "Symbol '%s' used, but not present in _call" % (n, ), node)

        return True
            

class IPOutlinerPass(gg.passes.Pass):
    depends = set(['KernelPropsPass', 'SemCheckedASTAvail', 'RWSetsPass', 'PreOptimizationPass'])

    def run(self, compiler, unit, gen, pm):
        v = CallChecker()
        v.visit3(compiler, unit.ast, gen)
        if compiler.errors: return False

        v = IterPipeOutliner()
        v.nodes_generated = False
        v.visit3(compiler, unit, unit.ast, gen)
        if v.nodes_generated:
            pm.set_nodes_generated()

        if compiler.options.outline_iterate_gb:
            v = DevOnlyKernels()
            v.nodes_generated = False
            v.visit3(compiler, unit, unit.ast, gen)
            if v.nodes_generated: pm.set_nodes_generated()

        return True

class IPOutlinerGBPass(gg.passes.Pass):
    depends = set(['IPOutlinerPass'])

    def run(self, compiler, unit, gen, pm):
        v = IterPipeOutlinerGBCheck()
        v.visit4(compiler, unit, unit.ast, gen)        

        v = IterPipeOutlinerGB()
        v.nodes_generated = False
        v.visit3(compiler, unit, unit.ast, gen)
        if v.nodes_generated: pm.set_nodes_generated()

        return True
